{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generative_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tensorflow\n",
        "!pip3 install keras"
      ],
      "metadata": {
        "id": "QccnwuPMkPFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tarek El-Hajjaoui\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding"
      ],
      "metadata": {
        "id": "6xmCldTofKro"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punc(word, punc_set = string.punctuation):\n",
        "  return ''.join(ch for ch in word if ch not in punc_set)"
      ],
      "metadata": {
        "id": "EMRTMJvD0oyQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the text from the file\n",
        "def gen_corpus_from_file(in_file=\"/content/nursery_rhymes.txt\", \n",
        "                         out_file=\"/content/parsed_txt.txt\"):\n",
        "  headers_lst = []\n",
        "  rhymes_lst = []\n",
        "  skip_ln = lambda ln : True if (ln == \"\") else False\n",
        "  is_header = lambda ln : True if (ln[-1].isupper()) else False\n",
        "  with open(in_file) as file:\n",
        "    for line in file:\n",
        "      strip_line = line.replace('\\r', ' ').replace('\\n', ' ').strip()\n",
        "      if skip_ln(strip_line): continue\n",
        "      if is_header(strip_line):\n",
        "        headers_lst.append(strip_line)\n",
        "      else:\n",
        "        rhyme = remove_punc(strip_line.lower())\n",
        "        rhymes_lst.append(rhyme)\n",
        "  rhymes = ' '.join(rhymes_lst)\n",
        "  del headers_lst\n",
        "  del rhymes_lst\n",
        "  with open(out_file, \"w\") as out_f:\n",
        "    out_f.write(rhymes)\n",
        "  return rhymes"
      ],
      "metadata": {
        "id": "5tEW5pZ9vg14"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = gen_corpus_from_file()"
      ],
      "metadata": {
        "id": "d3eZrrAGwFiq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Model\n",
        "class LSTM_Text_Generator():\n",
        "  def __init__(self, corpus, step_back, epochs):\n",
        "    # member variables\n",
        "    self.corpus = corpus\n",
        "    self.vocab_size = None\n",
        "    self.max_length = None\n",
        "    self.step_back = step_back\n",
        "    self.tokenizer = Tokenizer()\n",
        "    self.encoded = None\n",
        "    self.sequences = None\n",
        "    self.X = None\n",
        "    self.y = None\n",
        "    self.tokenize_words()\n",
        "    self.epochs = epochs\n",
        "    self.next_seq = ''\n",
        "    # Sequential is the base of the model\n",
        "    self.model = Sequential()\n",
        "  # integer encode sequences of words\n",
        "  def tokenize_words(self):\n",
        "    self.tokenizer.fit_on_texts([self.corpus])\n",
        "    self.encoded = self.tokenizer.texts_to_sequences([self.corpus])[0]\n",
        "    self.vocab_size = len(self.tokenizer.word_index) + 1\n",
        "    print(f'Vocabulary Size: {self.vocab_size}')\n",
        "  # encode step_back (2) words -> 1 word\n",
        "  def gen_sequences(self):\n",
        "    self.sequences = []\n",
        "    for i in range(self.step_back, len(self.encoded)):\n",
        "      sequence = self.encoded[i - self.step_back : i + 1]\n",
        "      self.sequences.append(sequence)\n",
        "    print(f'Total Sequences: {len(self.sequences)}')\n",
        "    # pad sequences\n",
        "    self.max_length = max([len(seq) for seq in self.sequences])\n",
        "    self.sequences = pad_sequences(self.sequences, maxlen=self.max_length, padding='pre')\n",
        "    print(f'Max Sequence Length: {self.max_length}')\n",
        "  def dist_data_X_y(self):\n",
        "    self.sequences = np.array(self.sequences)\n",
        "    # split into input and output elements\n",
        "    self.X, self.y = self.sequences[:,:-1], self.sequences[:,-1]\n",
        "    self.y = to_categorical(self.y, num_classes=self.vocab_size)\n",
        "  def pre_process(self):\n",
        "    self.gen_sequences()\n",
        "    self.dist_data_X_y()\n",
        "  # compile network\n",
        "  def compile(self):\n",
        "    self.pre_process()\n",
        "    self.model.add(Embedding(self.vocab_size, 10, input_length=self.max_length-1))\n",
        "    self.model.add(LSTM(50))\n",
        "    self.model.add(Dense(self.vocab_size, activation='softmax'))\n",
        "    self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  # fit network\n",
        "  def train(self):\n",
        "    self.model.fit(self.X, self.y, epochs=self.epochs, verbose=2)\n",
        "  def predict(self):\n",
        "    return self.model.predict(self.encoded, verbose=0)\n",
        "  def summary(self):\n",
        "    return self.model.summary()\n",
        "  def get_rand_word(self):\n",
        "    rand_word = ''\n",
        "    is_valid = False\n",
        "    while is_valid == False:\n",
        "      rand_word = self.corpus.split(' ')[random.randint(0, len(self.corpus.split(' ')) - 1)]\n",
        "      if rand_word != ' ' and len(rand_word) != 0:\n",
        "        is_valid = True\n",
        "    return rand_word\n",
        "  def reset_next_seq(self):\n",
        "    self.next_seq = ''\n",
        "  # generate a sequence from a language model\n",
        "  def generate_seq(self, seed_seq='', supress_msg=True):\n",
        "    if seed_seq == '':\n",
        "      if supress_msg == False:\n",
        "        print('No sequence was chosen, a random pair of words is being \\\n",
        "      chosen as the seed text.')\n",
        "      seed_seq = get_rand_word() + \" \" + get_rand_word()\n",
        "      if supress_msg == False:\n",
        "        print(f\"Random pair chosen: {seed_seq}\")\n",
        "    # when provide the model with a pair of words\n",
        "    in_text = seed_seq\n",
        "    # set the 2nd wor of current sequence as the first for the next sequence\n",
        "    self.next_seq = seed_seq.split(' ')[1]\n",
        "    # encode the text as integer\n",
        "    encoded = self.tokenizer.texts_to_sequences([in_text])[0]\n",
        "    # pre-pad sequences to a fixed length\n",
        "    encoded = pad_sequences([encoded], maxlen=self.max_length-1, padding='pre')\n",
        "    # predict probabilities for each word\n",
        "    predict = self.model.predict(encoded, verbose=0)\n",
        "    yhat=np.argmax(predict,axis=1)\n",
        "    # map predicted word index to word\n",
        "    out_word = ''\n",
        "    for word, index in self.tokenizer.word_index.items():\n",
        "      if index == yhat:\n",
        "        out_word = word\n",
        "        break\n",
        "    # append to input\n",
        "    in_text = out_word\n",
        "    # set the out word as the 2nd word for next_seq variable\n",
        "    self.next_seq += ' ' + out_word\n",
        "    return in_text\n"
      ],
      "metadata": {
        "id": "kV93oYK2RpfI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_nusery_rhymes(trained_model, n_lines=30,\n",
        "                      n_words = 20, output_file=\"lstm_rhymes.txt\"):\n",
        "  with open(output_file, \"w\") as out_file:\n",
        "    for i in range(n_lines):\n",
        "      msg = f\"Rhyme {i + 1}: \"\n",
        "      seed_pair = trained_model.get_rand_word() + \" \" + trained_model.get_rand_word()\n",
        "      curr_line = trained_model.generate_seq(seed_pair)\n",
        "      for n in range(n_words):\n",
        "        curr_line += \" \" + trained_model.generate_seq(trained_model.next_seq)\n",
        "      msg += curr_line\n",
        "      out_file.write(msg + '\\n')\n",
        "      msg = \"\"\n",
        "      curr_line = \"\""
      ],
      "metadata": {
        "id": "WPSuGOwOfEAf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model = LSTM_Text_Generator(corpus, 2, 400)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz-l_lyWaH7N",
        "outputId": "bc8ba115-4424-4af6-bdd0-5346cbebde8d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 2393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model.compile()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZs5Dbd6a0-b",
        "outputId": "05f26334-5536-45d1-ea8e-6d201bc88f36"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sequences: 15916\n",
            "Max Sequence Length: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfsygGEEs5F2",
        "outputId": "a433321f-626c-45c1-ef69-69ad2fefc684"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 2, 10)             23930     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50)                12200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2393)              122043    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 158,173\n",
            "Trainable params: 158,173\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model.train()"
      ],
      "metadata": {
        "id": "7cnQsSRQa4fA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faef24e5-d713-4d3a-9b12-6e2a6d13f70f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "498/498 - 7s - loss: 6.7005 - accuracy: 0.0503 - 7s/epoch - 13ms/step\n",
            "Epoch 2/400\n",
            "498/498 - 2s - loss: 6.2089 - accuracy: 0.0525 - 2s/epoch - 4ms/step\n",
            "Epoch 3/400\n",
            "498/498 - 2s - loss: 6.0889 - accuracy: 0.0545 - 2s/epoch - 4ms/step\n",
            "Epoch 4/400\n",
            "498/498 - 2s - loss: 5.9924 - accuracy: 0.0621 - 2s/epoch - 4ms/step\n",
            "Epoch 5/400\n",
            "498/498 - 2s - loss: 5.9136 - accuracy: 0.0647 - 2s/epoch - 4ms/step\n",
            "Epoch 6/400\n",
            "498/498 - 2s - loss: 5.8396 - accuracy: 0.0683 - 2s/epoch - 4ms/step\n",
            "Epoch 7/400\n",
            "498/498 - 2s - loss: 5.7582 - accuracy: 0.0724 - 2s/epoch - 4ms/step\n",
            "Epoch 8/400\n",
            "498/498 - 2s - loss: 5.6727 - accuracy: 0.0752 - 2s/epoch - 4ms/step\n",
            "Epoch 9/400\n",
            "498/498 - 2s - loss: 5.5863 - accuracy: 0.0794 - 2s/epoch - 4ms/step\n",
            "Epoch 10/400\n",
            "498/498 - 2s - loss: 5.5008 - accuracy: 0.0832 - 2s/epoch - 4ms/step\n",
            "Epoch 11/400\n",
            "498/498 - 2s - loss: 5.4150 - accuracy: 0.0908 - 2s/epoch - 4ms/step\n",
            "Epoch 12/400\n",
            "498/498 - 2s - loss: 5.3269 - accuracy: 0.0953 - 2s/epoch - 4ms/step\n",
            "Epoch 13/400\n",
            "498/498 - 2s - loss: 5.2353 - accuracy: 0.1005 - 2s/epoch - 4ms/step\n",
            "Epoch 14/400\n",
            "498/498 - 2s - loss: 5.1439 - accuracy: 0.1065 - 2s/epoch - 4ms/step\n",
            "Epoch 15/400\n",
            "498/498 - 2s - loss: 5.0530 - accuracy: 0.1126 - 2s/epoch - 4ms/step\n",
            "Epoch 16/400\n",
            "498/498 - 2s - loss: 4.9640 - accuracy: 0.1184 - 2s/epoch - 4ms/step\n",
            "Epoch 17/400\n",
            "498/498 - 2s - loss: 4.8758 - accuracy: 0.1245 - 2s/epoch - 4ms/step\n",
            "Epoch 18/400\n",
            "498/498 - 2s - loss: 4.7888 - accuracy: 0.1307 - 2s/epoch - 4ms/step\n",
            "Epoch 19/400\n",
            "498/498 - 2s - loss: 4.7029 - accuracy: 0.1354 - 2s/epoch - 4ms/step\n",
            "Epoch 20/400\n",
            "498/498 - 2s - loss: 4.6223 - accuracy: 0.1431 - 2s/epoch - 4ms/step\n",
            "Epoch 21/400\n",
            "498/498 - 2s - loss: 4.5396 - accuracy: 0.1499 - 2s/epoch - 4ms/step\n",
            "Epoch 22/400\n",
            "498/498 - 2s - loss: 4.4610 - accuracy: 0.1605 - 2s/epoch - 4ms/step\n",
            "Epoch 23/400\n",
            "498/498 - 2s - loss: 4.3828 - accuracy: 0.1693 - 2s/epoch - 4ms/step\n",
            "Epoch 24/400\n",
            "498/498 - 2s - loss: 4.3051 - accuracy: 0.1813 - 2s/epoch - 4ms/step\n",
            "Epoch 25/400\n",
            "498/498 - 2s - loss: 4.2281 - accuracy: 0.1924 - 2s/epoch - 4ms/step\n",
            "Epoch 26/400\n",
            "498/498 - 2s - loss: 4.1556 - accuracy: 0.2024 - 2s/epoch - 4ms/step\n",
            "Epoch 27/400\n",
            "498/498 - 2s - loss: 4.0841 - accuracy: 0.2133 - 2s/epoch - 4ms/step\n",
            "Epoch 28/400\n",
            "498/498 - 2s - loss: 4.0141 - accuracy: 0.2247 - 2s/epoch - 4ms/step\n",
            "Epoch 29/400\n",
            "498/498 - 2s - loss: 3.9483 - accuracy: 0.2344 - 2s/epoch - 4ms/step\n",
            "Epoch 30/400\n",
            "498/498 - 2s - loss: 3.8826 - accuracy: 0.2408 - 2s/epoch - 4ms/step\n",
            "Epoch 31/400\n",
            "498/498 - 2s - loss: 3.8204 - accuracy: 0.2520 - 2s/epoch - 4ms/step\n",
            "Epoch 32/400\n",
            "498/498 - 2s - loss: 3.7586 - accuracy: 0.2638 - 2s/epoch - 4ms/step\n",
            "Epoch 33/400\n",
            "498/498 - 2s - loss: 3.6999 - accuracy: 0.2720 - 2s/epoch - 4ms/step\n",
            "Epoch 34/400\n",
            "498/498 - 2s - loss: 3.6426 - accuracy: 0.2798 - 2s/epoch - 4ms/step\n",
            "Epoch 35/400\n",
            "498/498 - 2s - loss: 3.5856 - accuracy: 0.2902 - 2s/epoch - 4ms/step\n",
            "Epoch 36/400\n",
            "498/498 - 2s - loss: 3.5322 - accuracy: 0.2984 - 2s/epoch - 4ms/step\n",
            "Epoch 37/400\n",
            "498/498 - 2s - loss: 3.4786 - accuracy: 0.3050 - 2s/epoch - 4ms/step\n",
            "Epoch 38/400\n",
            "498/498 - 2s - loss: 3.4267 - accuracy: 0.3146 - 2s/epoch - 4ms/step\n",
            "Epoch 39/400\n",
            "498/498 - 2s - loss: 3.3757 - accuracy: 0.3206 - 2s/epoch - 4ms/step\n",
            "Epoch 40/400\n",
            "498/498 - 2s - loss: 3.3284 - accuracy: 0.3275 - 2s/epoch - 4ms/step\n",
            "Epoch 41/400\n",
            "498/498 - 2s - loss: 3.2803 - accuracy: 0.3378 - 2s/epoch - 4ms/step\n",
            "Epoch 42/400\n",
            "498/498 - 2s - loss: 3.2344 - accuracy: 0.3428 - 2s/epoch - 4ms/step\n",
            "Epoch 43/400\n",
            "498/498 - 2s - loss: 3.1898 - accuracy: 0.3508 - 2s/epoch - 4ms/step\n",
            "Epoch 44/400\n",
            "498/498 - 2s - loss: 3.1467 - accuracy: 0.3568 - 2s/epoch - 4ms/step\n",
            "Epoch 45/400\n",
            "498/498 - 2s - loss: 3.1036 - accuracy: 0.3643 - 2s/epoch - 4ms/step\n",
            "Epoch 46/400\n",
            "498/498 - 2s - loss: 3.0638 - accuracy: 0.3693 - 2s/epoch - 4ms/step\n",
            "Epoch 47/400\n",
            "498/498 - 2s - loss: 3.0226 - accuracy: 0.3791 - 2s/epoch - 4ms/step\n",
            "Epoch 48/400\n",
            "498/498 - 2s - loss: 2.9846 - accuracy: 0.3818 - 2s/epoch - 4ms/step\n",
            "Epoch 49/400\n",
            "498/498 - 2s - loss: 2.9459 - accuracy: 0.3912 - 2s/epoch - 4ms/step\n",
            "Epoch 50/400\n",
            "498/498 - 2s - loss: 2.9091 - accuracy: 0.3962 - 2s/epoch - 4ms/step\n",
            "Epoch 51/400\n",
            "498/498 - 2s - loss: 2.8724 - accuracy: 0.4018 - 2s/epoch - 4ms/step\n",
            "Epoch 52/400\n",
            "498/498 - 2s - loss: 2.8391 - accuracy: 0.4075 - 2s/epoch - 4ms/step\n",
            "Epoch 53/400\n",
            "498/498 - 2s - loss: 2.8064 - accuracy: 0.4134 - 2s/epoch - 4ms/step\n",
            "Epoch 54/400\n",
            "498/498 - 2s - loss: 2.7719 - accuracy: 0.4184 - 2s/epoch - 4ms/step\n",
            "Epoch 55/400\n",
            "498/498 - 2s - loss: 2.7396 - accuracy: 0.4234 - 2s/epoch - 4ms/step\n",
            "Epoch 56/400\n",
            "498/498 - 2s - loss: 2.7086 - accuracy: 0.4267 - 2s/epoch - 4ms/step\n",
            "Epoch 57/400\n",
            "498/498 - 2s - loss: 2.6778 - accuracy: 0.4352 - 2s/epoch - 4ms/step\n",
            "Epoch 58/400\n",
            "498/498 - 2s - loss: 2.6490 - accuracy: 0.4404 - 2s/epoch - 4ms/step\n",
            "Epoch 59/400\n",
            "498/498 - 2s - loss: 2.6199 - accuracy: 0.4441 - 2s/epoch - 4ms/step\n",
            "Epoch 60/400\n",
            "498/498 - 2s - loss: 2.5900 - accuracy: 0.4488 - 2s/epoch - 4ms/step\n",
            "Epoch 61/400\n",
            "498/498 - 2s - loss: 2.5628 - accuracy: 0.4561 - 2s/epoch - 4ms/step\n",
            "Epoch 62/400\n",
            "498/498 - 2s - loss: 2.5345 - accuracy: 0.4578 - 2s/epoch - 4ms/step\n",
            "Epoch 63/400\n",
            "498/498 - 2s - loss: 2.5085 - accuracy: 0.4661 - 2s/epoch - 4ms/step\n",
            "Epoch 64/400\n",
            "498/498 - 2s - loss: 2.4821 - accuracy: 0.4697 - 2s/epoch - 4ms/step\n",
            "Epoch 65/400\n",
            "498/498 - 2s - loss: 2.4581 - accuracy: 0.4711 - 2s/epoch - 4ms/step\n",
            "Epoch 66/400\n",
            "498/498 - 2s - loss: 2.4324 - accuracy: 0.4763 - 2s/epoch - 4ms/step\n",
            "Epoch 67/400\n",
            "498/498 - 2s - loss: 2.4080 - accuracy: 0.4813 - 2s/epoch - 4ms/step\n",
            "Epoch 68/400\n",
            "498/498 - 2s - loss: 2.3837 - accuracy: 0.4849 - 2s/epoch - 4ms/step\n",
            "Epoch 69/400\n",
            "498/498 - 2s - loss: 2.3621 - accuracy: 0.4894 - 2s/epoch - 4ms/step\n",
            "Epoch 70/400\n",
            "498/498 - 2s - loss: 2.3397 - accuracy: 0.4950 - 2s/epoch - 4ms/step\n",
            "Epoch 71/400\n",
            "498/498 - 2s - loss: 2.3178 - accuracy: 0.4963 - 2s/epoch - 4ms/step\n",
            "Epoch 72/400\n",
            "498/498 - 2s - loss: 2.2958 - accuracy: 0.5008 - 2s/epoch - 4ms/step\n",
            "Epoch 73/400\n",
            "498/498 - 2s - loss: 2.2763 - accuracy: 0.5036 - 2s/epoch - 4ms/step\n",
            "Epoch 74/400\n",
            "498/498 - 2s - loss: 2.2541 - accuracy: 0.5053 - 2s/epoch - 4ms/step\n",
            "Epoch 75/400\n",
            "498/498 - 2s - loss: 2.2360 - accuracy: 0.5099 - 2s/epoch - 4ms/step\n",
            "Epoch 76/400\n",
            "498/498 - 2s - loss: 2.2163 - accuracy: 0.5136 - 2s/epoch - 4ms/step\n",
            "Epoch 77/400\n",
            "498/498 - 2s - loss: 2.1971 - accuracy: 0.5156 - 2s/epoch - 4ms/step\n",
            "Epoch 78/400\n",
            "498/498 - 2s - loss: 2.1784 - accuracy: 0.5200 - 2s/epoch - 4ms/step\n",
            "Epoch 79/400\n",
            "498/498 - 2s - loss: 2.1608 - accuracy: 0.5195 - 2s/epoch - 4ms/step\n",
            "Epoch 80/400\n",
            "498/498 - 2s - loss: 2.1422 - accuracy: 0.5262 - 2s/epoch - 4ms/step\n",
            "Epoch 81/400\n",
            "498/498 - 2s - loss: 2.1247 - accuracy: 0.5292 - 2s/epoch - 4ms/step\n",
            "Epoch 82/400\n",
            "498/498 - 2s - loss: 2.1079 - accuracy: 0.5293 - 2s/epoch - 4ms/step\n",
            "Epoch 83/400\n",
            "498/498 - 2s - loss: 2.0919 - accuracy: 0.5319 - 2s/epoch - 4ms/step\n",
            "Epoch 84/400\n",
            "498/498 - 2s - loss: 2.0751 - accuracy: 0.5356 - 2s/epoch - 4ms/step\n",
            "Epoch 85/400\n",
            "498/498 - 2s - loss: 2.0587 - accuracy: 0.5375 - 2s/epoch - 4ms/step\n",
            "Epoch 86/400\n",
            "498/498 - 2s - loss: 2.0429 - accuracy: 0.5391 - 2s/epoch - 4ms/step\n",
            "Epoch 87/400\n",
            "498/498 - 2s - loss: 2.0275 - accuracy: 0.5427 - 2s/epoch - 4ms/step\n",
            "Epoch 88/400\n",
            "498/498 - 2s - loss: 2.0133 - accuracy: 0.5444 - 2s/epoch - 4ms/step\n",
            "Epoch 89/400\n",
            "498/498 - 2s - loss: 1.9991 - accuracy: 0.5491 - 2s/epoch - 4ms/step\n",
            "Epoch 90/400\n",
            "498/498 - 2s - loss: 1.9839 - accuracy: 0.5519 - 2s/epoch - 4ms/step\n",
            "Epoch 91/400\n",
            "498/498 - 2s - loss: 1.9707 - accuracy: 0.5545 - 2s/epoch - 4ms/step\n",
            "Epoch 92/400\n",
            "498/498 - 2s - loss: 1.9579 - accuracy: 0.5535 - 2s/epoch - 4ms/step\n",
            "Epoch 93/400\n",
            "498/498 - 2s - loss: 1.9430 - accuracy: 0.5555 - 2s/epoch - 4ms/step\n",
            "Epoch 94/400\n",
            "498/498 - 2s - loss: 1.9290 - accuracy: 0.5589 - 2s/epoch - 4ms/step\n",
            "Epoch 95/400\n",
            "498/498 - 2s - loss: 1.9187 - accuracy: 0.5593 - 2s/epoch - 4ms/step\n",
            "Epoch 96/400\n",
            "498/498 - 2s - loss: 1.9053 - accuracy: 0.5606 - 2s/epoch - 4ms/step\n",
            "Epoch 97/400\n",
            "498/498 - 2s - loss: 1.8924 - accuracy: 0.5660 - 2s/epoch - 4ms/step\n",
            "Epoch 98/400\n",
            "498/498 - 2s - loss: 1.8810 - accuracy: 0.5664 - 2s/epoch - 4ms/step\n",
            "Epoch 99/400\n",
            "498/498 - 2s - loss: 1.8690 - accuracy: 0.5689 - 2s/epoch - 4ms/step\n",
            "Epoch 100/400\n",
            "498/498 - 2s - loss: 1.8569 - accuracy: 0.5674 - 2s/epoch - 4ms/step\n",
            "Epoch 101/400\n",
            "498/498 - 2s - loss: 1.8455 - accuracy: 0.5706 - 2s/epoch - 4ms/step\n",
            "Epoch 102/400\n",
            "498/498 - 2s - loss: 1.8338 - accuracy: 0.5727 - 2s/epoch - 4ms/step\n",
            "Epoch 103/400\n",
            "498/498 - 2s - loss: 1.8239 - accuracy: 0.5716 - 2s/epoch - 4ms/step\n",
            "Epoch 104/400\n",
            "498/498 - 2s - loss: 1.8130 - accuracy: 0.5765 - 2s/epoch - 4ms/step\n",
            "Epoch 105/400\n",
            "498/498 - 2s - loss: 1.8016 - accuracy: 0.5765 - 2s/epoch - 4ms/step\n",
            "Epoch 106/400\n",
            "498/498 - 2s - loss: 1.7913 - accuracy: 0.5795 - 2s/epoch - 4ms/step\n",
            "Epoch 107/400\n",
            "498/498 - 2s - loss: 1.7812 - accuracy: 0.5820 - 2s/epoch - 4ms/step\n",
            "Epoch 108/400\n",
            "498/498 - 2s - loss: 1.7712 - accuracy: 0.5826 - 2s/epoch - 4ms/step\n",
            "Epoch 109/400\n",
            "498/498 - 2s - loss: 1.7609 - accuracy: 0.5833 - 2s/epoch - 4ms/step\n",
            "Epoch 110/400\n",
            "498/498 - 2s - loss: 1.7511 - accuracy: 0.5851 - 2s/epoch - 4ms/step\n",
            "Epoch 111/400\n",
            "498/498 - 2s - loss: 1.7428 - accuracy: 0.5845 - 2s/epoch - 4ms/step\n",
            "Epoch 112/400\n",
            "498/498 - 2s - loss: 1.7326 - accuracy: 0.5877 - 2s/epoch - 4ms/step\n",
            "Epoch 113/400\n",
            "498/498 - 2s - loss: 1.7233 - accuracy: 0.5887 - 2s/epoch - 4ms/step\n",
            "Epoch 114/400\n",
            "498/498 - 2s - loss: 1.7142 - accuracy: 0.5909 - 2s/epoch - 4ms/step\n",
            "Epoch 115/400\n",
            "498/498 - 2s - loss: 1.7048 - accuracy: 0.5912 - 2s/epoch - 4ms/step\n",
            "Epoch 116/400\n",
            "498/498 - 2s - loss: 1.6960 - accuracy: 0.5917 - 2s/epoch - 4ms/step\n",
            "Epoch 117/400\n",
            "498/498 - 2s - loss: 1.6873 - accuracy: 0.5955 - 2s/epoch - 4ms/step\n",
            "Epoch 118/400\n",
            "498/498 - 2s - loss: 1.6773 - accuracy: 0.5944 - 2s/epoch - 4ms/step\n",
            "Epoch 119/400\n",
            "498/498 - 2s - loss: 1.6704 - accuracy: 0.5981 - 2s/epoch - 4ms/step\n",
            "Epoch 120/400\n",
            "498/498 - 2s - loss: 1.6626 - accuracy: 0.5980 - 2s/epoch - 4ms/step\n",
            "Epoch 121/400\n",
            "498/498 - 2s - loss: 1.6551 - accuracy: 0.5990 - 2s/epoch - 4ms/step\n",
            "Epoch 122/400\n",
            "498/498 - 2s - loss: 1.6464 - accuracy: 0.5998 - 2s/epoch - 4ms/step\n",
            "Epoch 123/400\n",
            "498/498 - 2s - loss: 1.6394 - accuracy: 0.6020 - 2s/epoch - 4ms/step\n",
            "Epoch 124/400\n",
            "498/498 - 2s - loss: 1.6302 - accuracy: 0.6025 - 2s/epoch - 4ms/step\n",
            "Epoch 125/400\n",
            "498/498 - 2s - loss: 1.6237 - accuracy: 0.6027 - 2s/epoch - 4ms/step\n",
            "Epoch 126/400\n",
            "498/498 - 2s - loss: 1.6162 - accuracy: 0.6045 - 2s/epoch - 4ms/step\n",
            "Epoch 127/400\n",
            "498/498 - 2s - loss: 1.6095 - accuracy: 0.6035 - 2s/epoch - 4ms/step\n",
            "Epoch 128/400\n",
            "498/498 - 2s - loss: 1.5992 - accuracy: 0.6076 - 2s/epoch - 4ms/step\n",
            "Epoch 129/400\n",
            "498/498 - 2s - loss: 1.5931 - accuracy: 0.6079 - 2s/epoch - 4ms/step\n",
            "Epoch 130/400\n",
            "498/498 - 2s - loss: 1.5875 - accuracy: 0.6085 - 2s/epoch - 4ms/step\n",
            "Epoch 131/400\n",
            "498/498 - 2s - loss: 1.5791 - accuracy: 0.6099 - 2s/epoch - 4ms/step\n",
            "Epoch 132/400\n",
            "498/498 - 2s - loss: 1.5721 - accuracy: 0.6135 - 2s/epoch - 4ms/step\n",
            "Epoch 133/400\n",
            "498/498 - 2s - loss: 1.5653 - accuracy: 0.6131 - 2s/epoch - 4ms/step\n",
            "Epoch 134/400\n",
            "498/498 - 2s - loss: 1.5592 - accuracy: 0.6120 - 2s/epoch - 4ms/step\n",
            "Epoch 135/400\n",
            "498/498 - 2s - loss: 1.5527 - accuracy: 0.6145 - 2s/epoch - 4ms/step\n",
            "Epoch 136/400\n",
            "498/498 - 2s - loss: 1.5461 - accuracy: 0.6169 - 2s/epoch - 4ms/step\n",
            "Epoch 137/400\n",
            "498/498 - 2s - loss: 1.5390 - accuracy: 0.6154 - 2s/epoch - 4ms/step\n",
            "Epoch 138/400\n",
            "498/498 - 2s - loss: 1.5335 - accuracy: 0.6185 - 2s/epoch - 4ms/step\n",
            "Epoch 139/400\n",
            "498/498 - 2s - loss: 1.5271 - accuracy: 0.6164 - 2s/epoch - 4ms/step\n",
            "Epoch 140/400\n",
            "498/498 - 2s - loss: 1.5198 - accuracy: 0.6189 - 2s/epoch - 4ms/step\n",
            "Epoch 141/400\n",
            "498/498 - 2s - loss: 1.5142 - accuracy: 0.6215 - 2s/epoch - 4ms/step\n",
            "Epoch 142/400\n",
            "498/498 - 2s - loss: 1.5089 - accuracy: 0.6218 - 2s/epoch - 4ms/step\n",
            "Epoch 143/400\n",
            "498/498 - 2s - loss: 1.5017 - accuracy: 0.6215 - 2s/epoch - 4ms/step\n",
            "Epoch 144/400\n",
            "498/498 - 2s - loss: 1.4970 - accuracy: 0.6217 - 2s/epoch - 4ms/step\n",
            "Epoch 145/400\n",
            "498/498 - 2s - loss: 1.4904 - accuracy: 0.6235 - 2s/epoch - 4ms/step\n",
            "Epoch 146/400\n",
            "498/498 - 2s - loss: 1.4860 - accuracy: 0.6230 - 2s/epoch - 4ms/step\n",
            "Epoch 147/400\n",
            "498/498 - 2s - loss: 1.4795 - accuracy: 0.6250 - 2s/epoch - 4ms/step\n",
            "Epoch 148/400\n",
            "498/498 - 2s - loss: 1.4741 - accuracy: 0.6263 - 2s/epoch - 4ms/step\n",
            "Epoch 149/400\n",
            "498/498 - 2s - loss: 1.4693 - accuracy: 0.6245 - 2s/epoch - 4ms/step\n",
            "Epoch 150/400\n",
            "498/498 - 2s - loss: 1.4623 - accuracy: 0.6263 - 2s/epoch - 4ms/step\n",
            "Epoch 151/400\n",
            "498/498 - 2s - loss: 1.4570 - accuracy: 0.6290 - 2s/epoch - 4ms/step\n",
            "Epoch 152/400\n",
            "498/498 - 2s - loss: 1.4534 - accuracy: 0.6280 - 2s/epoch - 4ms/step\n",
            "Epoch 153/400\n",
            "498/498 - 2s - loss: 1.4470 - accuracy: 0.6321 - 2s/epoch - 4ms/step\n",
            "Epoch 154/400\n",
            "498/498 - 2s - loss: 1.4420 - accuracy: 0.6264 - 2s/epoch - 4ms/step\n",
            "Epoch 155/400\n",
            "498/498 - 2s - loss: 1.4372 - accuracy: 0.6323 - 2s/epoch - 4ms/step\n",
            "Epoch 156/400\n",
            "498/498 - 2s - loss: 1.4315 - accuracy: 0.6307 - 2s/epoch - 4ms/step\n",
            "Epoch 157/400\n",
            "498/498 - 2s - loss: 1.4276 - accuracy: 0.6313 - 2s/epoch - 4ms/step\n",
            "Epoch 158/400\n",
            "498/498 - 2s - loss: 1.4218 - accuracy: 0.6328 - 2s/epoch - 4ms/step\n",
            "Epoch 159/400\n",
            "498/498 - 2s - loss: 1.4175 - accuracy: 0.6314 - 2s/epoch - 4ms/step\n",
            "Epoch 160/400\n",
            "498/498 - 2s - loss: 1.4123 - accuracy: 0.6355 - 2s/epoch - 4ms/step\n",
            "Epoch 161/400\n",
            "498/498 - 2s - loss: 1.4079 - accuracy: 0.6359 - 2s/epoch - 4ms/step\n",
            "Epoch 162/400\n",
            "498/498 - 2s - loss: 1.4035 - accuracy: 0.6360 - 2s/epoch - 4ms/step\n",
            "Epoch 163/400\n",
            "498/498 - 2s - loss: 1.3984 - accuracy: 0.6367 - 2s/epoch - 4ms/step\n",
            "Epoch 164/400\n",
            "498/498 - 2s - loss: 1.3940 - accuracy: 0.6377 - 2s/epoch - 4ms/step\n",
            "Epoch 165/400\n",
            "498/498 - 2s - loss: 1.3911 - accuracy: 0.6372 - 2s/epoch - 4ms/step\n",
            "Epoch 166/400\n",
            "498/498 - 2s - loss: 1.3834 - accuracy: 0.6388 - 2s/epoch - 4ms/step\n",
            "Epoch 167/400\n",
            "498/498 - 2s - loss: 1.3803 - accuracy: 0.6394 - 2s/epoch - 4ms/step\n",
            "Epoch 168/400\n",
            "498/498 - 2s - loss: 1.3767 - accuracy: 0.6384 - 2s/epoch - 4ms/step\n",
            "Epoch 169/400\n",
            "498/498 - 2s - loss: 1.3726 - accuracy: 0.6401 - 2s/epoch - 4ms/step\n",
            "Epoch 170/400\n",
            "498/498 - 2s - loss: 1.3677 - accuracy: 0.6416 - 2s/epoch - 4ms/step\n",
            "Epoch 171/400\n",
            "498/498 - 2s - loss: 1.3640 - accuracy: 0.6414 - 2s/epoch - 4ms/step\n",
            "Epoch 172/400\n",
            "498/498 - 2s - loss: 1.3586 - accuracy: 0.6433 - 2s/epoch - 4ms/step\n",
            "Epoch 173/400\n",
            "498/498 - 2s - loss: 1.3559 - accuracy: 0.6422 - 2s/epoch - 4ms/step\n",
            "Epoch 174/400\n",
            "498/498 - 2s - loss: 1.3513 - accuracy: 0.6431 - 2s/epoch - 4ms/step\n",
            "Epoch 175/400\n",
            "498/498 - 2s - loss: 1.3464 - accuracy: 0.6446 - 2s/epoch - 4ms/step\n",
            "Epoch 176/400\n",
            "498/498 - 2s - loss: 1.3422 - accuracy: 0.6441 - 2s/epoch - 4ms/step\n",
            "Epoch 177/400\n",
            "498/498 - 2s - loss: 1.3391 - accuracy: 0.6458 - 2s/epoch - 4ms/step\n",
            "Epoch 178/400\n",
            "498/498 - 2s - loss: 1.3351 - accuracy: 0.6449 - 2s/epoch - 4ms/step\n",
            "Epoch 179/400\n",
            "498/498 - 2s - loss: 1.3316 - accuracy: 0.6449 - 2s/epoch - 4ms/step\n",
            "Epoch 180/400\n",
            "498/498 - 2s - loss: 1.3268 - accuracy: 0.6460 - 2s/epoch - 4ms/step\n",
            "Epoch 181/400\n",
            "498/498 - 2s - loss: 1.3241 - accuracy: 0.6486 - 2s/epoch - 4ms/step\n",
            "Epoch 182/400\n",
            "498/498 - 2s - loss: 1.3196 - accuracy: 0.6482 - 2s/epoch - 4ms/step\n",
            "Epoch 183/400\n",
            "498/498 - 2s - loss: 1.3170 - accuracy: 0.6499 - 2s/epoch - 4ms/step\n",
            "Epoch 184/400\n",
            "498/498 - 2s - loss: 1.3115 - accuracy: 0.6477 - 2s/epoch - 4ms/step\n",
            "Epoch 185/400\n",
            "498/498 - 2s - loss: 1.3090 - accuracy: 0.6483 - 2s/epoch - 4ms/step\n",
            "Epoch 186/400\n",
            "498/498 - 2s - loss: 1.3039 - accuracy: 0.6505 - 2s/epoch - 4ms/step\n",
            "Epoch 187/400\n",
            "498/498 - 2s - loss: 1.3009 - accuracy: 0.6500 - 2s/epoch - 4ms/step\n",
            "Epoch 188/400\n",
            "498/498 - 2s - loss: 1.2979 - accuracy: 0.6524 - 2s/epoch - 4ms/step\n",
            "Epoch 189/400\n",
            "498/498 - 2s - loss: 1.2931 - accuracy: 0.6534 - 2s/epoch - 4ms/step\n",
            "Epoch 190/400\n",
            "498/498 - 2s - loss: 1.2906 - accuracy: 0.6522 - 2s/epoch - 4ms/step\n",
            "Epoch 191/400\n",
            "498/498 - 2s - loss: 1.2873 - accuracy: 0.6527 - 2s/epoch - 4ms/step\n",
            "Epoch 192/400\n",
            "498/498 - 2s - loss: 1.2855 - accuracy: 0.6514 - 2s/epoch - 4ms/step\n",
            "Epoch 193/400\n",
            "498/498 - 2s - loss: 1.2799 - accuracy: 0.6566 - 2s/epoch - 4ms/step\n",
            "Epoch 194/400\n",
            "498/498 - 2s - loss: 1.2770 - accuracy: 0.6551 - 2s/epoch - 4ms/step\n",
            "Epoch 195/400\n",
            "498/498 - 2s - loss: 1.2737 - accuracy: 0.6544 - 2s/epoch - 4ms/step\n",
            "Epoch 196/400\n",
            "498/498 - 2s - loss: 1.2694 - accuracy: 0.6524 - 2s/epoch - 4ms/step\n",
            "Epoch 197/400\n",
            "498/498 - 2s - loss: 1.2683 - accuracy: 0.6539 - 2s/epoch - 4ms/step\n",
            "Epoch 198/400\n",
            "498/498 - 2s - loss: 1.2641 - accuracy: 0.6581 - 2s/epoch - 4ms/step\n",
            "Epoch 199/400\n",
            "498/498 - 2s - loss: 1.2611 - accuracy: 0.6577 - 2s/epoch - 4ms/step\n",
            "Epoch 200/400\n",
            "498/498 - 2s - loss: 1.2573 - accuracy: 0.6576 - 2s/epoch - 4ms/step\n",
            "Epoch 201/400\n",
            "498/498 - 2s - loss: 1.2536 - accuracy: 0.6593 - 2s/epoch - 4ms/step\n",
            "Epoch 202/400\n",
            "498/498 - 2s - loss: 1.2507 - accuracy: 0.6573 - 2s/epoch - 4ms/step\n",
            "Epoch 203/400\n",
            "498/498 - 2s - loss: 1.2481 - accuracy: 0.6564 - 2s/epoch - 4ms/step\n",
            "Epoch 204/400\n",
            "498/498 - 2s - loss: 1.2446 - accuracy: 0.6562 - 2s/epoch - 4ms/step\n",
            "Epoch 205/400\n",
            "498/498 - 2s - loss: 1.2421 - accuracy: 0.6589 - 2s/epoch - 4ms/step\n",
            "Epoch 206/400\n",
            "498/498 - 2s - loss: 1.2398 - accuracy: 0.6597 - 2s/epoch - 4ms/step\n",
            "Epoch 207/400\n",
            "498/498 - 2s - loss: 1.2353 - accuracy: 0.6613 - 2s/epoch - 4ms/step\n",
            "Epoch 208/400\n",
            "498/498 - 2s - loss: 1.2334 - accuracy: 0.6595 - 2s/epoch - 4ms/step\n",
            "Epoch 209/400\n",
            "498/498 - 2s - loss: 1.2292 - accuracy: 0.6618 - 2s/epoch - 4ms/step\n",
            "Epoch 210/400\n",
            "498/498 - 2s - loss: 1.2269 - accuracy: 0.6603 - 2s/epoch - 4ms/step\n",
            "Epoch 211/400\n",
            "498/498 - 2s - loss: 1.2244 - accuracy: 0.6634 - 2s/epoch - 4ms/step\n",
            "Epoch 212/400\n",
            "498/498 - 2s - loss: 1.2215 - accuracy: 0.6600 - 2s/epoch - 4ms/step\n",
            "Epoch 213/400\n",
            "498/498 - 2s - loss: 1.2182 - accuracy: 0.6615 - 2s/epoch - 4ms/step\n",
            "Epoch 214/400\n",
            "498/498 - 2s - loss: 1.2164 - accuracy: 0.6640 - 2s/epoch - 4ms/step\n",
            "Epoch 215/400\n",
            "498/498 - 2s - loss: 1.2129 - accuracy: 0.6630 - 2s/epoch - 4ms/step\n",
            "Epoch 216/400\n",
            "498/498 - 2s - loss: 1.2109 - accuracy: 0.6616 - 2s/epoch - 4ms/step\n",
            "Epoch 217/400\n",
            "498/498 - 2s - loss: 1.2074 - accuracy: 0.6653 - 2s/epoch - 4ms/step\n",
            "Epoch 218/400\n",
            "498/498 - 2s - loss: 1.2048 - accuracy: 0.6659 - 2s/epoch - 4ms/step\n",
            "Epoch 219/400\n",
            "498/498 - 2s - loss: 1.2021 - accuracy: 0.6632 - 2s/epoch - 4ms/step\n",
            "Epoch 220/400\n",
            "498/498 - 2s - loss: 1.1997 - accuracy: 0.6651 - 2s/epoch - 4ms/step\n",
            "Epoch 221/400\n",
            "498/498 - 2s - loss: 1.1964 - accuracy: 0.6646 - 2s/epoch - 4ms/step\n",
            "Epoch 222/400\n",
            "498/498 - 2s - loss: 1.1943 - accuracy: 0.6676 - 2s/epoch - 4ms/step\n",
            "Epoch 223/400\n",
            "498/498 - 2s - loss: 1.1914 - accuracy: 0.6658 - 2s/epoch - 4ms/step\n",
            "Epoch 224/400\n",
            "498/498 - 2s - loss: 1.1875 - accuracy: 0.6700 - 2s/epoch - 4ms/step\n",
            "Epoch 225/400\n",
            "498/498 - 2s - loss: 1.1846 - accuracy: 0.6669 - 2s/epoch - 4ms/step\n",
            "Epoch 226/400\n",
            "498/498 - 2s - loss: 1.1837 - accuracy: 0.6661 - 2s/epoch - 4ms/step\n",
            "Epoch 227/400\n",
            "498/498 - 2s - loss: 1.1815 - accuracy: 0.6673 - 2s/epoch - 4ms/step\n",
            "Epoch 228/400\n",
            "498/498 - 2s - loss: 1.1781 - accuracy: 0.6690 - 2s/epoch - 4ms/step\n",
            "Epoch 229/400\n",
            "498/498 - 2s - loss: 1.1755 - accuracy: 0.6689 - 2s/epoch - 4ms/step\n",
            "Epoch 230/400\n",
            "498/498 - 2s - loss: 1.1734 - accuracy: 0.6685 - 2s/epoch - 4ms/step\n",
            "Epoch 231/400\n",
            "498/498 - 2s - loss: 1.1725 - accuracy: 0.6675 - 2s/epoch - 4ms/step\n",
            "Epoch 232/400\n",
            "498/498 - 2s - loss: 1.1680 - accuracy: 0.6681 - 2s/epoch - 4ms/step\n",
            "Epoch 233/400\n",
            "498/498 - 2s - loss: 1.1651 - accuracy: 0.6691 - 2s/epoch - 4ms/step\n",
            "Epoch 234/400\n",
            "498/498 - 2s - loss: 1.1635 - accuracy: 0.6728 - 2s/epoch - 4ms/step\n",
            "Epoch 235/400\n",
            "498/498 - 2s - loss: 1.1608 - accuracy: 0.6709 - 2s/epoch - 4ms/step\n",
            "Epoch 236/400\n",
            "498/498 - 2s - loss: 1.1584 - accuracy: 0.6706 - 2s/epoch - 4ms/step\n",
            "Epoch 237/400\n",
            "498/498 - 2s - loss: 1.1563 - accuracy: 0.6696 - 2s/epoch - 4ms/step\n",
            "Epoch 238/400\n",
            "498/498 - 2s - loss: 1.1544 - accuracy: 0.6699 - 2s/epoch - 4ms/step\n",
            "Epoch 239/400\n",
            "498/498 - 2s - loss: 1.1519 - accuracy: 0.6718 - 2s/epoch - 4ms/step\n",
            "Epoch 240/400\n",
            "498/498 - 2s - loss: 1.1487 - accuracy: 0.6703 - 2s/epoch - 4ms/step\n",
            "Epoch 241/400\n",
            "498/498 - 2s - loss: 1.1468 - accuracy: 0.6737 - 2s/epoch - 4ms/step\n",
            "Epoch 242/400\n",
            "498/498 - 2s - loss: 1.1452 - accuracy: 0.6711 - 2s/epoch - 4ms/step\n",
            "Epoch 243/400\n",
            "498/498 - 2s - loss: 1.1431 - accuracy: 0.6740 - 2s/epoch - 4ms/step\n",
            "Epoch 244/400\n",
            "498/498 - 2s - loss: 1.1403 - accuracy: 0.6725 - 2s/epoch - 4ms/step\n",
            "Epoch 245/400\n",
            "498/498 - 2s - loss: 1.1386 - accuracy: 0.6764 - 2s/epoch - 4ms/step\n",
            "Epoch 246/400\n",
            "498/498 - 2s - loss: 1.1360 - accuracy: 0.6749 - 2s/epoch - 4ms/step\n",
            "Epoch 247/400\n",
            "498/498 - 2s - loss: 1.1330 - accuracy: 0.6754 - 2s/epoch - 4ms/step\n",
            "Epoch 248/400\n",
            "498/498 - 2s - loss: 1.1312 - accuracy: 0.6733 - 2s/epoch - 4ms/step\n",
            "Epoch 249/400\n",
            "498/498 - 2s - loss: 1.1307 - accuracy: 0.6733 - 2s/epoch - 4ms/step\n",
            "Epoch 250/400\n",
            "498/498 - 2s - loss: 1.1276 - accuracy: 0.6736 - 2s/epoch - 4ms/step\n",
            "Epoch 251/400\n",
            "498/498 - 2s - loss: 1.1256 - accuracy: 0.6736 - 2s/epoch - 4ms/step\n",
            "Epoch 252/400\n",
            "498/498 - 2s - loss: 1.1232 - accuracy: 0.6733 - 2s/epoch - 4ms/step\n",
            "Epoch 253/400\n",
            "498/498 - 2s - loss: 1.1214 - accuracy: 0.6750 - 2s/epoch - 4ms/step\n",
            "Epoch 254/400\n",
            "498/498 - 2s - loss: 1.1190 - accuracy: 0.6782 - 2s/epoch - 4ms/step\n",
            "Epoch 255/400\n",
            "498/498 - 2s - loss: 1.1182 - accuracy: 0.6743 - 2s/epoch - 4ms/step\n",
            "Epoch 256/400\n",
            "498/498 - 2s - loss: 1.1150 - accuracy: 0.6762 - 2s/epoch - 4ms/step\n",
            "Epoch 257/400\n",
            "498/498 - 2s - loss: 1.1119 - accuracy: 0.6792 - 2s/epoch - 4ms/step\n",
            "Epoch 258/400\n",
            "498/498 - 2s - loss: 1.1101 - accuracy: 0.6809 - 2s/epoch - 4ms/step\n",
            "Epoch 259/400\n",
            "498/498 - 2s - loss: 1.1097 - accuracy: 0.6780 - 2s/epoch - 4ms/step\n",
            "Epoch 260/400\n",
            "498/498 - 2s - loss: 1.1059 - accuracy: 0.6760 - 2s/epoch - 4ms/step\n",
            "Epoch 261/400\n",
            "498/498 - 2s - loss: 1.1045 - accuracy: 0.6780 - 2s/epoch - 4ms/step\n",
            "Epoch 262/400\n",
            "498/498 - 2s - loss: 1.1030 - accuracy: 0.6784 - 2s/epoch - 4ms/step\n",
            "Epoch 263/400\n",
            "498/498 - 2s - loss: 1.1010 - accuracy: 0.6799 - 2s/epoch - 4ms/step\n",
            "Epoch 264/400\n",
            "498/498 - 2s - loss: 1.0982 - accuracy: 0.6805 - 2s/epoch - 4ms/step\n",
            "Epoch 265/400\n",
            "498/498 - 2s - loss: 1.0973 - accuracy: 0.6798 - 2s/epoch - 4ms/step\n",
            "Epoch 266/400\n",
            "498/498 - 2s - loss: 1.0957 - accuracy: 0.6782 - 2s/epoch - 4ms/step\n",
            "Epoch 267/400\n",
            "498/498 - 2s - loss: 1.0943 - accuracy: 0.6808 - 2s/epoch - 4ms/step\n",
            "Epoch 268/400\n",
            "498/498 - 2s - loss: 1.0929 - accuracy: 0.6793 - 2s/epoch - 4ms/step\n",
            "Epoch 269/400\n",
            "498/498 - 2s - loss: 1.0889 - accuracy: 0.6802 - 2s/epoch - 4ms/step\n",
            "Epoch 270/400\n",
            "498/498 - 2s - loss: 1.0883 - accuracy: 0.6810 - 2s/epoch - 4ms/step\n",
            "Epoch 271/400\n",
            "498/498 - 2s - loss: 1.0866 - accuracy: 0.6786 - 2s/epoch - 4ms/step\n",
            "Epoch 272/400\n",
            "498/498 - 2s - loss: 1.0845 - accuracy: 0.6812 - 2s/epoch - 4ms/step\n",
            "Epoch 273/400\n",
            "498/498 - 2s - loss: 1.0829 - accuracy: 0.6836 - 2s/epoch - 4ms/step\n",
            "Epoch 274/400\n",
            "498/498 - 2s - loss: 1.0802 - accuracy: 0.6828 - 2s/epoch - 4ms/step\n",
            "Epoch 275/400\n",
            "498/498 - 2s - loss: 1.0803 - accuracy: 0.6799 - 2s/epoch - 4ms/step\n",
            "Epoch 276/400\n",
            "498/498 - 2s - loss: 1.0770 - accuracy: 0.6808 - 2s/epoch - 4ms/step\n",
            "Epoch 277/400\n",
            "498/498 - 2s - loss: 1.0745 - accuracy: 0.6824 - 2s/epoch - 4ms/step\n",
            "Epoch 278/400\n",
            "498/498 - 2s - loss: 1.0746 - accuracy: 0.6837 - 2s/epoch - 4ms/step\n",
            "Epoch 279/400\n",
            "498/498 - 2s - loss: 1.0715 - accuracy: 0.6825 - 2s/epoch - 4ms/step\n",
            "Epoch 280/400\n",
            "498/498 - 2s - loss: 1.0703 - accuracy: 0.6826 - 2s/epoch - 4ms/step\n",
            "Epoch 281/400\n",
            "498/498 - 2s - loss: 1.0686 - accuracy: 0.6835 - 2s/epoch - 4ms/step\n",
            "Epoch 282/400\n",
            "498/498 - 2s - loss: 1.0679 - accuracy: 0.6828 - 2s/epoch - 4ms/step\n",
            "Epoch 283/400\n",
            "498/498 - 2s - loss: 1.0643 - accuracy: 0.6825 - 2s/epoch - 4ms/step\n",
            "Epoch 284/400\n",
            "498/498 - 2s - loss: 1.0638 - accuracy: 0.6834 - 2s/epoch - 4ms/step\n",
            "Epoch 285/400\n",
            "498/498 - 2s - loss: 1.0615 - accuracy: 0.6856 - 2s/epoch - 4ms/step\n",
            "Epoch 286/400\n",
            "498/498 - 2s - loss: 1.0609 - accuracy: 0.6853 - 2s/epoch - 4ms/step\n",
            "Epoch 287/400\n",
            "498/498 - 2s - loss: 1.0575 - accuracy: 0.6848 - 2s/epoch - 4ms/step\n",
            "Epoch 288/400\n",
            "498/498 - 2s - loss: 1.0583 - accuracy: 0.6826 - 2s/epoch - 4ms/step\n",
            "Epoch 289/400\n",
            "498/498 - 2s - loss: 1.0537 - accuracy: 0.6865 - 2s/epoch - 4ms/step\n",
            "Epoch 290/400\n",
            "498/498 - 2s - loss: 1.0555 - accuracy: 0.6815 - 2s/epoch - 4ms/step\n",
            "Epoch 291/400\n",
            "498/498 - 2s - loss: 1.0536 - accuracy: 0.6842 - 2s/epoch - 4ms/step\n",
            "Epoch 292/400\n",
            "498/498 - 2s - loss: 1.0505 - accuracy: 0.6845 - 2s/epoch - 4ms/step\n",
            "Epoch 293/400\n",
            "498/498 - 2s - loss: 1.0508 - accuracy: 0.6847 - 2s/epoch - 4ms/step\n",
            "Epoch 294/400\n",
            "498/498 - 2s - loss: 1.0468 - accuracy: 0.6853 - 2s/epoch - 4ms/step\n",
            "Epoch 295/400\n",
            "498/498 - 2s - loss: 1.0453 - accuracy: 0.6842 - 2s/epoch - 4ms/step\n",
            "Epoch 296/400\n",
            "498/498 - 2s - loss: 1.0457 - accuracy: 0.6850 - 2s/epoch - 4ms/step\n",
            "Epoch 297/400\n",
            "498/498 - 2s - loss: 1.0434 - accuracy: 0.6859 - 2s/epoch - 4ms/step\n",
            "Epoch 298/400\n",
            "498/498 - 2s - loss: 1.0410 - accuracy: 0.6860 - 2s/epoch - 4ms/step\n",
            "Epoch 299/400\n",
            "498/498 - 2s - loss: 1.0399 - accuracy: 0.6851 - 2s/epoch - 4ms/step\n",
            "Epoch 300/400\n",
            "498/498 - 2s - loss: 1.0380 - accuracy: 0.6848 - 2s/epoch - 4ms/step\n",
            "Epoch 301/400\n",
            "498/498 - 2s - loss: 1.0374 - accuracy: 0.6894 - 2s/epoch - 4ms/step\n",
            "Epoch 302/400\n",
            "498/498 - 2s - loss: 1.0370 - accuracy: 0.6855 - 2s/epoch - 4ms/step\n",
            "Epoch 303/400\n",
            "498/498 - 2s - loss: 1.0339 - accuracy: 0.6868 - 2s/epoch - 4ms/step\n",
            "Epoch 304/400\n",
            "498/498 - 2s - loss: 1.0317 - accuracy: 0.6871 - 2s/epoch - 4ms/step\n",
            "Epoch 305/400\n",
            "498/498 - 2s - loss: 1.0305 - accuracy: 0.6871 - 2s/epoch - 4ms/step\n",
            "Epoch 306/400\n",
            "498/498 - 2s - loss: 1.0310 - accuracy: 0.6870 - 2s/epoch - 4ms/step\n",
            "Epoch 307/400\n",
            "498/498 - 2s - loss: 1.0288 - accuracy: 0.6876 - 2s/epoch - 4ms/step\n",
            "Epoch 308/400\n",
            "498/498 - 2s - loss: 1.0267 - accuracy: 0.6862 - 2s/epoch - 4ms/step\n",
            "Epoch 309/400\n",
            "498/498 - 2s - loss: 1.0260 - accuracy: 0.6892 - 2s/epoch - 4ms/step\n",
            "Epoch 310/400\n",
            "498/498 - 2s - loss: 1.0244 - accuracy: 0.6862 - 2s/epoch - 4ms/step\n",
            "Epoch 311/400\n",
            "498/498 - 2s - loss: 1.0222 - accuracy: 0.6867 - 2s/epoch - 4ms/step\n",
            "Epoch 312/400\n",
            "498/498 - 2s - loss: 1.0212 - accuracy: 0.6881 - 2s/epoch - 4ms/step\n",
            "Epoch 313/400\n",
            "498/498 - 2s - loss: 1.0205 - accuracy: 0.6879 - 2s/epoch - 4ms/step\n",
            "Epoch 314/400\n",
            "498/498 - 2s - loss: 1.0175 - accuracy: 0.6873 - 2s/epoch - 4ms/step\n",
            "Epoch 315/400\n",
            "498/498 - 2s - loss: 1.0181 - accuracy: 0.6892 - 2s/epoch - 4ms/step\n",
            "Epoch 316/400\n",
            "498/498 - 2s - loss: 1.0149 - accuracy: 0.6891 - 2s/epoch - 4ms/step\n",
            "Epoch 317/400\n",
            "498/498 - 2s - loss: 1.0143 - accuracy: 0.6884 - 2s/epoch - 4ms/step\n",
            "Epoch 318/400\n",
            "498/498 - 2s - loss: 1.0137 - accuracy: 0.6888 - 2s/epoch - 4ms/step\n",
            "Epoch 319/400\n",
            "498/498 - 2s - loss: 1.0125 - accuracy: 0.6890 - 2s/epoch - 4ms/step\n",
            "Epoch 320/400\n",
            "498/498 - 2s - loss: 1.0098 - accuracy: 0.6872 - 2s/epoch - 4ms/step\n",
            "Epoch 321/400\n",
            "498/498 - 2s - loss: 1.0097 - accuracy: 0.6882 - 2s/epoch - 4ms/step\n",
            "Epoch 322/400\n",
            "498/498 - 2s - loss: 1.0079 - accuracy: 0.6896 - 2s/epoch - 4ms/step\n",
            "Epoch 323/400\n",
            "498/498 - 2s - loss: 1.0051 - accuracy: 0.6902 - 2s/epoch - 4ms/step\n",
            "Epoch 324/400\n",
            "498/498 - 2s - loss: 1.0065 - accuracy: 0.6907 - 2s/epoch - 4ms/step\n",
            "Epoch 325/400\n",
            "498/498 - 2s - loss: 1.0030 - accuracy: 0.6905 - 2s/epoch - 4ms/step\n",
            "Epoch 326/400\n",
            "498/498 - 2s - loss: 1.0035 - accuracy: 0.6896 - 2s/epoch - 4ms/step\n",
            "Epoch 327/400\n",
            "498/498 - 2s - loss: 1.0010 - accuracy: 0.6920 - 2s/epoch - 4ms/step\n",
            "Epoch 328/400\n",
            "498/498 - 2s - loss: 0.9984 - accuracy: 0.6926 - 2s/epoch - 4ms/step\n",
            "Epoch 329/400\n",
            "498/498 - 2s - loss: 0.9981 - accuracy: 0.6913 - 2s/epoch - 4ms/step\n",
            "Epoch 330/400\n",
            "498/498 - 2s - loss: 0.9974 - accuracy: 0.6919 - 2s/epoch - 4ms/step\n",
            "Epoch 331/400\n",
            "498/498 - 2s - loss: 0.9955 - accuracy: 0.6924 - 2s/epoch - 4ms/step\n",
            "Epoch 332/400\n",
            "498/498 - 2s - loss: 0.9941 - accuracy: 0.6943 - 2s/epoch - 4ms/step\n",
            "Epoch 333/400\n",
            "498/498 - 2s - loss: 0.9935 - accuracy: 0.6934 - 2s/epoch - 4ms/step\n",
            "Epoch 334/400\n",
            "498/498 - 2s - loss: 0.9920 - accuracy: 0.6922 - 2s/epoch - 4ms/step\n",
            "Epoch 335/400\n",
            "498/498 - 2s - loss: 0.9931 - accuracy: 0.6902 - 2s/epoch - 4ms/step\n",
            "Epoch 336/400\n",
            "498/498 - 2s - loss: 0.9895 - accuracy: 0.6928 - 2s/epoch - 4ms/step\n",
            "Epoch 337/400\n",
            "498/498 - 2s - loss: 0.9899 - accuracy: 0.6901 - 2s/epoch - 4ms/step\n",
            "Epoch 338/400\n",
            "498/498 - 2s - loss: 0.9886 - accuracy: 0.6923 - 2s/epoch - 4ms/step\n",
            "Epoch 339/400\n",
            "498/498 - 2s - loss: 0.9876 - accuracy: 0.6922 - 2s/epoch - 4ms/step\n",
            "Epoch 340/400\n",
            "498/498 - 2s - loss: 0.9836 - accuracy: 0.6939 - 2s/epoch - 4ms/step\n",
            "Epoch 341/400\n",
            "498/498 - 2s - loss: 0.9858 - accuracy: 0.6915 - 2s/epoch - 4ms/step\n",
            "Epoch 342/400\n",
            "498/498 - 2s - loss: 0.9832 - accuracy: 0.6941 - 2s/epoch - 4ms/step\n",
            "Epoch 343/400\n",
            "498/498 - 2s - loss: 0.9823 - accuracy: 0.6935 - 2s/epoch - 4ms/step\n",
            "Epoch 344/400\n",
            "498/498 - 2s - loss: 0.9800 - accuracy: 0.6916 - 2s/epoch - 4ms/step\n",
            "Epoch 345/400\n",
            "498/498 - 2s - loss: 0.9806 - accuracy: 0.6915 - 2s/epoch - 4ms/step\n",
            "Epoch 346/400\n",
            "498/498 - 2s - loss: 0.9786 - accuracy: 0.6948 - 2s/epoch - 4ms/step\n",
            "Epoch 347/400\n",
            "498/498 - 2s - loss: 0.9779 - accuracy: 0.6928 - 2s/epoch - 4ms/step\n",
            "Epoch 348/400\n",
            "498/498 - 2s - loss: 0.9760 - accuracy: 0.6942 - 2s/epoch - 4ms/step\n",
            "Epoch 349/400\n",
            "498/498 - 2s - loss: 0.9751 - accuracy: 0.6953 - 2s/epoch - 4ms/step\n",
            "Epoch 350/400\n",
            "498/498 - 2s - loss: 0.9738 - accuracy: 0.6938 - 2s/epoch - 4ms/step\n",
            "Epoch 351/400\n",
            "498/498 - 2s - loss: 0.9728 - accuracy: 0.6963 - 2s/epoch - 4ms/step\n",
            "Epoch 352/400\n",
            "498/498 - 2s - loss: 0.9725 - accuracy: 0.6913 - 2s/epoch - 4ms/step\n",
            "Epoch 353/400\n",
            "498/498 - 2s - loss: 0.9701 - accuracy: 0.6930 - 2s/epoch - 4ms/step\n",
            "Epoch 354/400\n",
            "498/498 - 2s - loss: 0.9684 - accuracy: 0.6967 - 2s/epoch - 4ms/step\n",
            "Epoch 355/400\n",
            "498/498 - 2s - loss: 0.9697 - accuracy: 0.6950 - 2s/epoch - 4ms/step\n",
            "Epoch 356/400\n",
            "498/498 - 2s - loss: 0.9672 - accuracy: 0.6952 - 2s/epoch - 4ms/step\n",
            "Epoch 357/400\n",
            "498/498 - 2s - loss: 0.9657 - accuracy: 0.6963 - 2s/epoch - 4ms/step\n",
            "Epoch 358/400\n",
            "498/498 - 2s - loss: 0.9653 - accuracy: 0.6932 - 2s/epoch - 4ms/step\n",
            "Epoch 359/400\n",
            "498/498 - 2s - loss: 0.9629 - accuracy: 0.6951 - 2s/epoch - 4ms/step\n",
            "Epoch 360/400\n",
            "498/498 - 2s - loss: 0.9628 - accuracy: 0.6943 - 2s/epoch - 4ms/step\n",
            "Epoch 361/400\n",
            "498/498 - 2s - loss: 0.9624 - accuracy: 0.6950 - 2s/epoch - 4ms/step\n",
            "Epoch 362/400\n",
            "498/498 - 2s - loss: 0.9606 - accuracy: 0.6937 - 2s/epoch - 4ms/step\n",
            "Epoch 363/400\n",
            "498/498 - 2s - loss: 0.9594 - accuracy: 0.6964 - 2s/epoch - 4ms/step\n",
            "Epoch 364/400\n",
            "498/498 - 2s - loss: 0.9588 - accuracy: 0.6952 - 2s/epoch - 4ms/step\n",
            "Epoch 365/400\n",
            "498/498 - 2s - loss: 0.9580 - accuracy: 0.6970 - 2s/epoch - 4ms/step\n",
            "Epoch 366/400\n",
            "498/498 - 2s - loss: 0.9566 - accuracy: 0.6962 - 2s/epoch - 4ms/step\n",
            "Epoch 367/400\n",
            "498/498 - 2s - loss: 0.9560 - accuracy: 0.6953 - 2s/epoch - 4ms/step\n",
            "Epoch 368/400\n",
            "498/498 - 2s - loss: 0.9536 - accuracy: 0.6966 - 2s/epoch - 4ms/step\n",
            "Epoch 369/400\n",
            "498/498 - 2s - loss: 0.9537 - accuracy: 0.6971 - 2s/epoch - 4ms/step\n",
            "Epoch 370/400\n",
            "498/498 - 2s - loss: 0.9515 - accuracy: 0.6967 - 2s/epoch - 4ms/step\n",
            "Epoch 371/400\n",
            "498/498 - 2s - loss: 0.9523 - accuracy: 0.6968 - 2s/epoch - 4ms/step\n",
            "Epoch 372/400\n",
            "498/498 - 2s - loss: 0.9484 - accuracy: 0.6985 - 2s/epoch - 4ms/step\n",
            "Epoch 373/400\n",
            "498/498 - 2s - loss: 0.9505 - accuracy: 0.6968 - 2s/epoch - 4ms/step\n",
            "Epoch 374/400\n",
            "498/498 - 2s - loss: 0.9496 - accuracy: 0.6937 - 2s/epoch - 4ms/step\n",
            "Epoch 375/400\n",
            "498/498 - 2s - loss: 0.9469 - accuracy: 0.6994 - 2s/epoch - 4ms/step\n",
            "Epoch 376/400\n",
            "498/498 - 2s - loss: 0.9470 - accuracy: 0.6987 - 2s/epoch - 4ms/step\n",
            "Epoch 377/400\n",
            "498/498 - 2s - loss: 0.9466 - accuracy: 0.6992 - 2s/epoch - 4ms/step\n",
            "Epoch 378/400\n",
            "498/498 - 2s - loss: 0.9446 - accuracy: 0.6972 - 2s/epoch - 4ms/step\n",
            "Epoch 379/400\n",
            "498/498 - 2s - loss: 0.9451 - accuracy: 0.6975 - 2s/epoch - 4ms/step\n",
            "Epoch 380/400\n",
            "498/498 - 2s - loss: 0.9439 - accuracy: 0.6992 - 2s/epoch - 4ms/step\n",
            "Epoch 381/400\n",
            "498/498 - 2s - loss: 0.9420 - accuracy: 0.6972 - 2s/epoch - 4ms/step\n",
            "Epoch 382/400\n",
            "498/498 - 2s - loss: 0.9406 - accuracy: 0.6987 - 2s/epoch - 4ms/step\n",
            "Epoch 383/400\n",
            "498/498 - 2s - loss: 0.9385 - accuracy: 0.6991 - 2s/epoch - 4ms/step\n",
            "Epoch 384/400\n",
            "498/498 - 2s - loss: 0.9390 - accuracy: 0.6989 - 2s/epoch - 4ms/step\n",
            "Epoch 385/400\n",
            "498/498 - 2s - loss: 0.9390 - accuracy: 0.6975 - 2s/epoch - 4ms/step\n",
            "Epoch 386/400\n",
            "498/498 - 2s - loss: 0.9379 - accuracy: 0.6967 - 2s/epoch - 4ms/step\n",
            "Epoch 387/400\n",
            "498/498 - 2s - loss: 0.9365 - accuracy: 0.6995 - 2s/epoch - 4ms/step\n",
            "Epoch 388/400\n",
            "498/498 - 2s - loss: 0.9353 - accuracy: 0.6973 - 2s/epoch - 4ms/step\n",
            "Epoch 389/400\n",
            "498/498 - 2s - loss: 0.9347 - accuracy: 0.6972 - 2s/epoch - 4ms/step\n",
            "Epoch 390/400\n",
            "498/498 - 2s - loss: 0.9335 - accuracy: 0.6989 - 2s/epoch - 4ms/step\n",
            "Epoch 391/400\n",
            "498/498 - 2s - loss: 0.9318 - accuracy: 0.7009 - 2s/epoch - 4ms/step\n",
            "Epoch 392/400\n",
            "498/498 - 2s - loss: 0.9308 - accuracy: 0.6987 - 2s/epoch - 4ms/step\n",
            "Epoch 393/400\n",
            "498/498 - 2s - loss: 0.9309 - accuracy: 0.7002 - 2s/epoch - 4ms/step\n",
            "Epoch 394/400\n",
            "498/498 - 2s - loss: 0.9297 - accuracy: 0.6994 - 2s/epoch - 4ms/step\n",
            "Epoch 395/400\n",
            "498/498 - 2s - loss: 0.9292 - accuracy: 0.6997 - 2s/epoch - 4ms/step\n",
            "Epoch 396/400\n",
            "498/498 - 2s - loss: 0.9283 - accuracy: 0.6997 - 2s/epoch - 4ms/step\n",
            "Epoch 397/400\n",
            "498/498 - 2s - loss: 0.9276 - accuracy: 0.7004 - 2s/epoch - 4ms/step\n",
            "Epoch 398/400\n",
            "498/498 - 2s - loss: 0.9266 - accuracy: 0.6994 - 2s/epoch - 4ms/step\n",
            "Epoch 399/400\n",
            "498/498 - 2s - loss: 0.9263 - accuracy: 0.7001 - 2s/epoch - 4ms/step\n",
            "Epoch 400/400\n",
            "498/498 - 2s - loss: 0.9249 - accuracy: 0.7003 - 2s/epoch - 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_nusery_rhymes(LSTM_Model, 30,\n",
        "                  20, \"lst_rhymes.txt\")"
      ],
      "metadata": {
        "id": "cVp48XhwfaC3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model_2 = LSTM_Text_Generator(corpus, 2, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUUKt0S_FAsL",
        "outputId": "82eca679-3276-4ddd-fe9c-52c713f9c9c6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 2393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model_2.compile()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow7EoovUFIeY",
        "outputId": "87e1bd4f-3372-44fc-8764-5a6d84c3648e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sequences: 15916\n",
            "Max Sequence Length: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdMo1E_wF9Vj",
        "outputId": "dcbfad2c-4499-4cd7-daef-fe3de3b4a5e4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 2, 10)             23930     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50)                12200     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2393)              122043    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 158,173\n",
            "Trainable params: 158,173\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model_2.train()"
      ],
      "metadata": {
        "id": "xqTasOFPFLTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93f11a3f-e32c-41c6-bd22-1f929bcf7129"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "498/498 - 4s - loss: 6.7023 - accuracy: 0.0513 - 4s/epoch - 7ms/step\n",
            "Epoch 2/50\n",
            "498/498 - 2s - loss: 6.2352 - accuracy: 0.0517 - 2s/epoch - 4ms/step\n",
            "Epoch 3/50\n",
            "498/498 - 2s - loss: 6.1415 - accuracy: 0.0525 - 2s/epoch - 4ms/step\n",
            "Epoch 4/50\n",
            "498/498 - 2s - loss: 6.0654 - accuracy: 0.0524 - 2s/epoch - 4ms/step\n",
            "Epoch 5/50\n",
            "498/498 - 2s - loss: 6.0110 - accuracy: 0.0528 - 2s/epoch - 4ms/step\n",
            "Epoch 6/50\n",
            "498/498 - 2s - loss: 5.9646 - accuracy: 0.0558 - 2s/epoch - 4ms/step\n",
            "Epoch 7/50\n",
            "498/498 - 2s - loss: 5.9072 - accuracy: 0.0648 - 2s/epoch - 4ms/step\n",
            "Epoch 8/50\n",
            "498/498 - 2s - loss: 5.8345 - accuracy: 0.0712 - 2s/epoch - 4ms/step\n",
            "Epoch 9/50\n",
            "498/498 - 2s - loss: 5.7496 - accuracy: 0.0749 - 2s/epoch - 4ms/step\n",
            "Epoch 10/50\n",
            "498/498 - 2s - loss: 5.6632 - accuracy: 0.0769 - 2s/epoch - 4ms/step\n",
            "Epoch 11/50\n",
            "498/498 - 2s - loss: 5.5824 - accuracy: 0.0794 - 2s/epoch - 4ms/step\n",
            "Epoch 12/50\n",
            "498/498 - 2s - loss: 5.5089 - accuracy: 0.0839 - 2s/epoch - 4ms/step\n",
            "Epoch 13/50\n",
            "498/498 - 2s - loss: 5.4373 - accuracy: 0.0860 - 2s/epoch - 4ms/step\n",
            "Epoch 14/50\n",
            "498/498 - 2s - loss: 5.3658 - accuracy: 0.0892 - 2s/epoch - 4ms/step\n",
            "Epoch 15/50\n",
            "498/498 - 2s - loss: 5.2912 - accuracy: 0.0932 - 2s/epoch - 4ms/step\n",
            "Epoch 16/50\n",
            "498/498 - 2s - loss: 5.2159 - accuracy: 0.1003 - 2s/epoch - 4ms/step\n",
            "Epoch 17/50\n",
            "498/498 - 2s - loss: 5.1374 - accuracy: 0.1059 - 2s/epoch - 4ms/step\n",
            "Epoch 18/50\n",
            "498/498 - 2s - loss: 5.0567 - accuracy: 0.1141 - 2s/epoch - 4ms/step\n",
            "Epoch 19/50\n",
            "498/498 - 2s - loss: 4.9741 - accuracy: 0.1221 - 2s/epoch - 4ms/step\n",
            "Epoch 20/50\n",
            "498/498 - 2s - loss: 4.8901 - accuracy: 0.1317 - 2s/epoch - 4ms/step\n",
            "Epoch 21/50\n",
            "498/498 - 2s - loss: 4.8029 - accuracy: 0.1397 - 2s/epoch - 4ms/step\n",
            "Epoch 22/50\n",
            "498/498 - 2s - loss: 4.7182 - accuracy: 0.1478 - 2s/epoch - 4ms/step\n",
            "Epoch 23/50\n",
            "498/498 - 2s - loss: 4.6328 - accuracy: 0.1583 - 2s/epoch - 4ms/step\n",
            "Epoch 24/50\n",
            "498/498 - 2s - loss: 4.5486 - accuracy: 0.1685 - 2s/epoch - 4ms/step\n",
            "Epoch 25/50\n",
            "498/498 - 2s - loss: 4.4646 - accuracy: 0.1781 - 2s/epoch - 4ms/step\n",
            "Epoch 26/50\n",
            "498/498 - 2s - loss: 4.3801 - accuracy: 0.1885 - 2s/epoch - 4ms/step\n",
            "Epoch 27/50\n",
            "498/498 - 2s - loss: 4.3014 - accuracy: 0.1994 - 2s/epoch - 4ms/step\n",
            "Epoch 28/50\n",
            "498/498 - 2s - loss: 4.2251 - accuracy: 0.2078 - 2s/epoch - 4ms/step\n",
            "Epoch 29/50\n",
            "498/498 - 2s - loss: 4.1520 - accuracy: 0.2143 - 2s/epoch - 4ms/step\n",
            "Epoch 30/50\n",
            "498/498 - 2s - loss: 4.0810 - accuracy: 0.2273 - 2s/epoch - 4ms/step\n",
            "Epoch 31/50\n",
            "498/498 - 2s - loss: 4.0125 - accuracy: 0.2343 - 2s/epoch - 4ms/step\n",
            "Epoch 32/50\n",
            "498/498 - 2s - loss: 3.9462 - accuracy: 0.2430 - 2s/epoch - 4ms/step\n",
            "Epoch 33/50\n",
            "498/498 - 2s - loss: 3.8802 - accuracy: 0.2508 - 2s/epoch - 4ms/step\n",
            "Epoch 34/50\n",
            "498/498 - 2s - loss: 3.8180 - accuracy: 0.2606 - 2s/epoch - 4ms/step\n",
            "Epoch 35/50\n",
            "498/498 - 2s - loss: 3.7562 - accuracy: 0.2669 - 2s/epoch - 4ms/step\n",
            "Epoch 36/50\n",
            "498/498 - 2s - loss: 3.6975 - accuracy: 0.2739 - 2s/epoch - 4ms/step\n",
            "Epoch 37/50\n",
            "498/498 - 2s - loss: 3.6399 - accuracy: 0.2810 - 2s/epoch - 4ms/step\n",
            "Epoch 38/50\n",
            "498/498 - 2s - loss: 3.5834 - accuracy: 0.2893 - 2s/epoch - 4ms/step\n",
            "Epoch 39/50\n",
            "498/498 - 2s - loss: 3.5296 - accuracy: 0.2989 - 2s/epoch - 4ms/step\n",
            "Epoch 40/50\n",
            "498/498 - 2s - loss: 3.4767 - accuracy: 0.3074 - 2s/epoch - 4ms/step\n",
            "Epoch 41/50\n",
            "498/498 - 2s - loss: 3.4259 - accuracy: 0.3134 - 2s/epoch - 4ms/step\n",
            "Epoch 42/50\n",
            "498/498 - 2s - loss: 3.3759 - accuracy: 0.3192 - 2s/epoch - 4ms/step\n",
            "Epoch 43/50\n",
            "498/498 - 2s - loss: 3.3268 - accuracy: 0.3280 - 2s/epoch - 4ms/step\n",
            "Epoch 44/50\n",
            "498/498 - 2s - loss: 3.2800 - accuracy: 0.3336 - 2s/epoch - 4ms/step\n",
            "Epoch 45/50\n",
            "498/498 - 2s - loss: 3.2342 - accuracy: 0.3409 - 2s/epoch - 4ms/step\n",
            "Epoch 46/50\n",
            "498/498 - 2s - loss: 3.1908 - accuracy: 0.3483 - 2s/epoch - 4ms/step\n",
            "Epoch 47/50\n",
            "498/498 - 2s - loss: 3.1463 - accuracy: 0.3566 - 2s/epoch - 4ms/step\n",
            "Epoch 48/50\n",
            "498/498 - 2s - loss: 3.1059 - accuracy: 0.3642 - 2s/epoch - 4ms/step\n",
            "Epoch 49/50\n",
            "498/498 - 2s - loss: 3.0638 - accuracy: 0.3678 - 2s/epoch - 4ms/step\n",
            "Epoch 50/50\n",
            "498/498 - 2s - loss: 3.0257 - accuracy: 0.3749 - 2s/epoch - 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_nusery_rhymes(LSTM_Model_2, 30,\n",
        "                  20, \"lst_rhymes_2.txt\")"
      ],
      "metadata": {
        "id": "PQJaIK2oF_Lw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sources\n",
        "- Jason Brownlee article: https://machinelearningmastery.com/develop-word-based-neural-language-models-python-keras/\n",
        "- https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/"
      ],
      "metadata": {
        "id": "GoN0Rc1ItR-i"
      }
    }
  ]
}