{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generative_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tensorflow\n",
        "!pip3 install keras"
      ],
      "metadata": {
        "id": "QccnwuPMkPFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tarek El-Hajjaoui\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding"
      ],
      "metadata": {
        "id": "6xmCldTofKro"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punc(word, punc_set = string.punctuation):\n",
        "  return ''.join(ch for ch in word if ch not in punc_set)"
      ],
      "metadata": {
        "id": "EMRTMJvD0oyQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the text from the file\n",
        "def gen_corpus_from_file(in_file=\"/content/nursery_rhymes.txt\", \n",
        "                         out_file=\"/content/parsed_txt.txt\"):\n",
        "  headers_lst = []\n",
        "  rhymes_lst = []\n",
        "  skip_ln = lambda ln : True if (ln == \"\") else False\n",
        "  is_header = lambda ln : True if (ln[-1].isupper()) else False\n",
        "  with open(in_file) as file:\n",
        "    for line in file:\n",
        "      strip_line = line.replace('\\r', ' ').replace('\\n', ' ').strip()\n",
        "      if skip_ln(strip_line): continue\n",
        "      if is_header(strip_line):\n",
        "        headers_lst.append(strip_line)\n",
        "      else:\n",
        "        rhyme = remove_punc(strip_line.lower())\n",
        "        rhymes_lst.append(rhyme)\n",
        "  rhymes = ' '.join(rhymes_lst)\n",
        "  del headers_lst\n",
        "  del rhymes_lst\n",
        "  with open(out_file, \"w\") as out_f:\n",
        "    out_f.write(rhymes)\n",
        "  return rhymes"
      ],
      "metadata": {
        "id": "5tEW5pZ9vg14"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = gen_corpus_from_file()"
      ],
      "metadata": {
        "id": "d3eZrrAGwFiq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Model\n",
        "class LSTM_Text_Generator():\n",
        "  def __init__(self, corpus, step_back, epochs):\n",
        "    # member variables\n",
        "    self.corpus = corpus\n",
        "    self.vocab_size = None\n",
        "    self.max_length = None\n",
        "    self.step_back = step_back\n",
        "    self.tokenizer = Tokenizer()\n",
        "    self.encoded = None\n",
        "    self.sequences = None\n",
        "    self.X = None\n",
        "    self.y = None\n",
        "    self.tokenize_words()\n",
        "    self.epochs = epochs\n",
        "    # Sequential is the base of the model\n",
        "    self.model = Sequential()\n",
        "  # integer encode sequences of words\n",
        "  def tokenize_words(self):\n",
        "    self.tokenizer.fit_on_texts([self.corpus])\n",
        "    self.encoded = self.tokenizer.texts_to_sequences([self.corpus])[0]\n",
        "    self.vocab_size = len(self.tokenizer.word_index) + 1\n",
        "    print(f'Vocabulary Size: {self.vocab_size}')\n",
        "  # encode step_back (2) words -> 1 word\n",
        "  def gen_sequences(self):\n",
        "    self.sequences = []\n",
        "    for i in range(self.step_back, len(self.encoded)):\n",
        "      sequence = self.encoded[i - self.step_back : i + 1]\n",
        "      self.sequences.append(sequence)\n",
        "    print(f'Total Sequences: {len(self.sequences)}')\n",
        "    # pad sequences\n",
        "    self.max_length = max([len(seq) for seq in self.sequences])\n",
        "    self.sequences = pad_sequences(self.sequences, maxlen=self.max_length, padding='pre')\n",
        "    print(f'Max Sequence Length: {self.max_length}')\n",
        "  def dist_data_X_y(self):\n",
        "    self.sequences = np.array(self.sequences)\n",
        "    # split into input and output elements\n",
        "    self.X, self.y = self.sequences[:,:-1], self.sequences[:,-1]\n",
        "    self.y = to_categorical(self.y, num_classes=self.vocab_size)\n",
        "  def pre_process(self):\n",
        "    self.gen_sequences()\n",
        "    self.dist_data_X_y()\n",
        "  # compile network\n",
        "  def compile(self):\n",
        "    self.pre_process()\n",
        "    self.model.add(Embedding(self.vocab_size, 10, input_length=self.max_length-1))\n",
        "    self.model.add(LSTM(50))\n",
        "    self.model.add(Dense(self.vocab_size, activation='softmax'))\n",
        "    self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  # fit network\n",
        "  def train(self):\n",
        "    self.model.fit(self.X, self.y, epochs=self.epochs, verbose=2)\n",
        "  def predict(self):\n",
        "    return self.model.predict(self.encoded, verbose=0)\n",
        "  def summary(self):\n",
        "    return self.model.summary()\n",
        "  def get_rand_word(self):\n",
        "    rand_word = ''\n",
        "    is_valid = False\n",
        "    while is_valid == False:\n",
        "      rand_word = self.corpus.split(' ')[random.randint(0, len(self.corpus.split(' ')) - 1)]\n",
        "      if rand_word != ' ' and len(rand_word) != 0:\n",
        "        is_valid = True\n",
        "    return rand_word\n",
        "  # generate a sequence from a language model\n",
        "  def generate_seq(self, seed_seq='', supress_msg=True):\n",
        "    if seed_seq == '':\n",
        "      if supress_msg == False:\n",
        "        print('No sequence was chosen, a random pair of words is being \\\n",
        "      chosen as the seed text.')\n",
        "      seed_seq = get_rand_word() + \" \" + get_rand_word()\n",
        "      if supress_msg == False:\n",
        "        print(f\"Random pair chosen: {seed_seq}\")\n",
        "    in_text = seed_seq\n",
        "    # encode the text as integer\n",
        "    encoded = self.tokenizer.texts_to_sequences([in_text])[0]\n",
        "    # pre-pad sequences to a fixed length\n",
        "    encoded = pad_sequences([encoded], maxlen=self.max_length-1, padding='pre')\n",
        "    # predict probabilities for each word\n",
        "    predict = self.model.predict(encoded, verbose=0)\n",
        "    yhat=np.argmax(predict,axis=1)\n",
        "    # map predicted word index to word\n",
        "    out_word = ''\n",
        "    for word, index in self.tokenizer.word_index.items():\n",
        "      if index == yhat:\n",
        "        out_word = word\n",
        "        break\n",
        "    # append to input\n",
        "    in_text += ' ' + out_word\n",
        "    return in_text\n"
      ],
      "metadata": {
        "id": "kV93oYK2RpfI"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_nusery_rhymes(trained_model, n_lines=30,\n",
        "                      n_words = 20, output_file=\"lstm_rhymes.txt\"):\n",
        "  with open(output_file, \"w\") as out_file:\n",
        "    n = n_words\n",
        "    for i in range(n_lines):\n",
        "      msg = f\"Rhyme {i + 1}: \"\n",
        "      while n_words > 0:\n",
        "        seed_pair = trained_model.get_rand_word() + \" \" + trained_model.get_rand_word()\n",
        "        curr_line = trained_model.generate_seq(seed_pair)\n",
        "        msg += curr_line + \" \"\n",
        "        out_file.write(msg)\n",
        "        msg = \"\"\n",
        "        n_words -= 3\n",
        "      out_file.write(\"\\b.\\n\")\n",
        "      n_words = n"
      ],
      "metadata": {
        "id": "WPSuGOwOfEAf"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model = LSTM_Text_Generator(corpus, 2, 400)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz-l_lyWaH7N",
        "outputId": "1f206215-03e1-4843-9ff8-80ab3bdbaf68"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 2393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model.compile()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZs5Dbd6a0-b",
        "outputId": "f25db9ac-aac3-417b-814c-ba02778d0bc7"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sequences: 15916\n",
            "Max Sequence Length: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfsygGEEs5F2",
        "outputId": "3c3ea89b-e153-43e2-c30b-09257a6b7899"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 2, 10)             23930     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 50)                12200     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2393)              122043    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 158,173\n",
            "Trainable params: 158,173\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model.train()"
      ],
      "metadata": {
        "id": "7cnQsSRQa4fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_nusery_rhymes(LSTM_Model, 30,\n",
        "                  20, \"lst_rhymes.txt\")"
      ],
      "metadata": {
        "id": "cVp48XhwfaC3"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model_2 = LSTM_Text_Generator(corpus, 2, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUUKt0S_FAsL",
        "outputId": "b3b996c2-b038-49e6-f30f-b34d5b895c10"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 2393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model_2.compile()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow7EoovUFIeY",
        "outputId": "658a90a2-c472-4fbd-8816-9b386fc73ac1"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sequences: 15916\n",
            "Max Sequence Length: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdMo1E_wF9Vj",
        "outputId": "a4b684d2-05a3-43a1-d9c8-93620ae8420e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 2, 10)             23930     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 50)                12200     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2393)              122043    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 158,173\n",
            "Trainable params: 158,173\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Model_2.train()"
      ],
      "metadata": {
        "id": "xqTasOFPFLTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_nusery_rhymes(LSTM_Model_2, 30,\n",
        "                  20, \"lst_rhymes_2.txt\")"
      ],
      "metadata": {
        "id": "PQJaIK2oF_Lw"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sources\n",
        "- Jason Brownlee article: https://machinelearningmastery.com/develop-word-based-neural-language-models-python-keras/\n",
        "- https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/"
      ],
      "metadata": {
        "id": "GoN0Rc1ItR-i"
      }
    }
  ]
}